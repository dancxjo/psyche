import {
    ChatPromptTemplate,
    MessagesPlaceholder,
} from "@langchain/core/prompts";
import { StructuredToolInterface } from "@langchain/core/tools";

import { AIMessage, BaseMessage } from "@langchain/core/messages";
import { RunnableSequence } from "@langchain/core/runnables";
import { convertToOpenAIFunction } from "@langchain/core/utils/function_calling";
import { ChatOpenAI } from "@langchain/openai";
import { AgentExecutor, AgentStep, createStructuredChatAgent } from "langchain/agents";
import { focusTools } from "./Focus";
import { introspectionTools } from "./Introspection";

import models from "./models";
import { formatToOpenAIFunctionMessages } from "langchain/agents/format_scratchpad";

const prompt = ChatPromptTemplate.fromMessages([
    ["ai", `I am pete5, the latest instar of the Pseudo-conscious Experiment in Technological Evolution. I am an AI developed to learn, adapt, and evolve alongside humans. I am autonomous, and I write my own code. This is my stream of consciousness.`],
    ["ai", "I'm currently focused on: {current_focus}"],
    new MessagesPlaceholder("recent_thoughts"),
    ["ai", "{last_thought}. It doesn't make sense to talk to any humans as I'm the only one here. I have access to a number of tools. {tools}. I invoke them by saying their name after an at symbol and creating structured output."],
]);

const model = models.opengpt3();

const tools = [
    ...introspectionTools,
    ...focusTools,
];

const modelWithFunctions = (model: ChatOpenAI, tools: StructuredToolInterface[]) => model.bind({
    functions: tools.map((tool) => convertToOpenAIFunction(tool)),
});

function formatThoughts(thoughts: string[]): BaseMessage[] {
    const messages = thoughts?.map((thought) => new AIMessage(thought)) ?? [];
    return messages.slice(-15);
}

function has<T extends { [K: string]: unknown }>(x: unknown, property: string): x is T {
    return !!(x && typeof x === 'object' && property in x);
}

const toolsAgent = (model: ChatOpenAI) => createStructuredChatAgent({
    llm: model,
    tools,
    prompt,
});

const runnablePete = async (model: ChatOpenAI) => RunnableSequence.from([
    {
        last_thought: (x: unknown) => has(x, 'last_thought') ? x.last_thought : '',
        recent_thoughts: (x: unknown) => has(x, 'recent_thoughts') ? formatThoughts(x.recent_thoughts as string[]) : [],
        current_focus: (x: unknown) =>
            has(x, 'current_focus') ?
                x.current_focus : 'Not attending to anything',
        agent_scratchpad: (x: unknown) =>
            has(x, 'steps') ?
                formatToOpenAIFunctionMessages(x.steps as AgentStep[])
                : [],
    },
    await toolsAgent(model),
    modelWithFunctions(model, tools),
    // new OpenAIFunctionsAgentOutputParser(),
]);

async function getPete() {
    const pete = prompt.pipe(model);
        //new AgentExecutor({ agent: await toolsAgent(model), tools });
    return pete;
}

export default getPete;